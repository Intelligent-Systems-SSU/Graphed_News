"""  
ë‰´ìŠ¤ ê¸°ì‚¬ì™€ ì§ˆì˜ì‘ë‹µì„ ì¢…í•©í•˜ì—¬ ìµœì¢… ê²°ê³¼ë¥¼ ìƒì„±í•˜ëŠ” ëª¨ë“ˆ  
"""  
from typing import List, Dict, Any, Optional  
from pydantic import BaseModel, Field  
from langchain_core.prompts import ChatPromptTemplate  
from langchain_openai import ChatOpenAI  
from .utils import load_model_config, load_prompt  

  
class FinalReport(BaseModel):  
    """êµ¬ì¡°í™”ëœ ìµœì¢… ë³´ê³ ì„œ ìŠ¤í‚¤ë§ˆ"""  
    overview: str = Field(description="ì‚¬ê±´ì˜ ê°œìš” ë° ë°°ê²½")
    key_points: str = Field(description="ì£¼ìš” í¬ì¸íŠ¸ë“¤") 
    main_reports: str = Field(description="ì‚¬ì‹¤ ì •ë¦¬ ë° ì£¼ìš” ë‚´ìš© ì„¤ëª…")  
    analysis: str = Field(description="ë¶„ì„ ë° ì›ì¸")  
    impact: str = Field(description="ì˜í–¥ ë° ë¬¸ì œì ")  
    resolution_nextsteps: str = Field(description="í•´ê²° ì¡°ì¹˜ ë˜ëŠ” í–¥í›„ ì¡°ì¹˜")  
    summary_recommendations: str = Field(description="ìš”ì•½ ë° ì œì–¸")  
    
    qa_insights: str = Field(description="ì§ˆì˜ì‘ë‹µì—ì„œ ì–»ì€ í†µì°°")  
  
  
class NewsAccumulator:  
    def __init__(self):  
        """  
        ë‰´ìŠ¤ Accumulator ì´ˆê¸°í™”  
          
        Args:  
            model_name (str): ì‚¬ìš©í•  OpenAI ëª¨ë¸ëª…  
            temperature (float): ìƒì„± ë‹¤ì–‘ì„± ì¡°ì ˆ ê°’  
        """  
        config = load_model_config('news_accumulator')
        self.llm = ChatOpenAI(**config)  
      
    def _format_qa(self, answers: List[Dict[str, str]]) -> str:  
        """ì§ˆì˜ì‘ë‹µ ëª©ë¡ì„ ë¬¸ìì—´ í˜•íƒœë¡œ ë³€í™˜"""  
        return "\n".join([f"Q: {list(item.keys())[0]}\nA: {list(item.values())[0]}" for item in answers])  
  
    def _generate_structured_report(self, news_content: Dict[str, Any], qa: List[Dict[str, str]], ka: List[Dict[str, str]]) -> FinalReport:  
        """ìµœì¢… ìš”ì•½ ìƒì„±"""            
        prompt_template = load_prompt('news_accumulator_prompt.yaml')
        prompt = ChatPromptTemplate.from_template(prompt_template)  
          
        # êµ¬ì¡°í™”ëœ ì¶œë ¥ì„ ìœ„í•œ LLM ì„¤ì •
        structured_llm = self.llm.with_structured_output(FinalReport)

        # ì‹¤ì œ ì…ë ¥ ë°ì´í„° ì¤€ë¹„
        input_data = {
            "extracted_content": news_content['content'],  
            "qa": self._format_qa(qa),
            "ka": self._format_qa(ka)
        }
        
        """debugìš©: í”„ë¡¬í”„íŠ¸ í¬ë§·íŒ… í™•ì¸"""
        # ì‹¤ì œ í”„ë¡¬í”„íŠ¸ í¬ë§·íŒ…í•´ì„œ í™•ì¸
        formatted_messages = prompt.format_messages(**input_data)
        
        print("=" * 80)
        print("ğŸ” ì‹¤ì œ LLMì— ì „ì†¡ë˜ëŠ” í”„ë¡¬í”„íŠ¸:")
        print("=" * 80)
        for i, message in enumerate(formatted_messages):
            print(f"Message {i+1} ({message.type}):")
            print(f"{message.content}")
            print("-" * 60)
        print("=" * 80)
        """debugìš©: í”„ë¡¬í”„íŠ¸ í¬ë§·íŒ… í™•ì¸"""
        
        chain = prompt | structured_llm  
        result = chain.invoke(input_data)  
            
        # ê²°ê³¼ê°€ ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš° FinalReportë¡œ ë³€í™˜
        if isinstance(result, dict):
            return FinalReport(**result)
        return result
            
    def process(self, news_content: Dict[str, Any], qa: List[Dict[str, str]], ka: List[Dict[str, str]]) -> str:  
        """  
        ë‰´ìŠ¤ ë‚´ìš©ê³¼ ì§ˆì˜ì‘ë‹µì„ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ê²°ê³¼ ìƒì„±  
          
        Args:  
            news_content (Dict[str, Any]): ì •ì œëœ ë‰´ìŠ¤ ê¸°ì‚¬ ë‚´ìš©  
            answers (List[Dict[str, str]]): ì§ˆë¬¸ê³¼ ë‹µë³€ ìŒì˜ ëª©ë¡  
              
        Returns:  
            FinalReport: êµ¬ì¡°í™”ëœ ìµœì¢… ë³´ê³ ì„œ  
        """  
        report = self._generate_structured_report(news_content, qa, ka)  

        # ìµœì¢… ë³´ê³ ì„œë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜
        doc = f"""
### {news_content['topic']}

#### ê°œìš” ë° ë°°ê²½
{report.overview}

#### ì£¼ìš” í¬ì¸íŠ¸
{report.key_points}

#### ì‚¬ì‹¤ ì •ë¦¬ ë° ì£¼ìš” ë‚´ìš©
{report.main_reports}

#### ë¶„ì„ ë° ì›ì¸
{report.analysis}

#### ì˜í–¥ ë° ë¬¸ì œì 
{report.impact}

#### í•´ê²° ì¡°ì¹˜ ë˜ëŠ” í–¥í›„ ì¡°ì¹˜
{report.resolution_nextsteps}

#### ìš”ì•½ ë° ì œì–¸
{report.summary_recommendations}

#### ì§ˆì˜ì‘ë‹µ í†µì°°
{report.qa_insights}
    """

        return doc
  